{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4c30af-7f25-4979-b95f-072658768859",
   "metadata": {},
   "source": [
    "## Extract UMAP embeddings for CFReT CP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9267d545-c6fe-4982-bb9b-41e25d3b8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jenna/mambaforge/envs/python_analysis_cfret/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/jenna/mambaforge/envs/python_analysis_cfret/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/jenna/mambaforge/envs/python_analysis_cfret/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/jenna/mambaforge/envs/python_analysis_cfret/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import umap\n",
    "import numpy as np\n",
    "\n",
    "from pycytominer import feature_select\n",
    "from pycytominer.cyto_utils import infer_cp_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d144be8",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Whole Plates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc71fa",
   "metadata": {},
   "source": [
    "### Set constant for whole plates\n",
    "\n",
    "Note: All plates (1-4) without filtering had a random seed of 1234. For plates with filtering, we use a random seed of 0 which is a standard for the Way lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0769ce32-b238-4a90-a0ab-a76688a66256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants (previously set prior, normally use 0 but the change in coordinates will impact already generated single-cell crops)\n",
    "umap_random_seed = 1234\n",
    "umap_n_components = 2\n",
    "\n",
    "output_dir = pathlib.Path(\"results\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f73df3",
   "metadata": {},
   "source": [
    "### Set paths to all plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a527f37-ad44-4a64-ac3d-6a1de7eff458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../3.process_cfret_features/data/single_cell_profiles/localhost220513100001_KK22-05-198_FactinAdjusted_sc_feature_selected.parquet',\n",
       " '../../../3.process_cfret_features/data/single_cell_profiles/localhost220512140003_KK22-05-198_sc_feature_selected.parquet',\n",
       " '../../../3.process_cfret_features/data/single_cell_profiles/localhost230405150001_sc_feature_selected.parquet',\n",
       " '../../../3.process_cfret_features/data/single_cell_profiles/localhost231120090001_sc_feature_selected.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set input paths\n",
    "data_dir = pathlib.Path(\"..\", \"..\", \"..\", \"3.process_cfret_features\", \"data\", \"single_cell_profiles\")\n",
    "\n",
    "# Select only the feature selected files\n",
    "file_suffix = \"*sc_feature_selected.parquet\"\n",
    "\n",
    "# Obtain file paths for all feature selected plates\n",
    "fs_files = glob.glob(f\"{data_dir}/{file_suffix}\")\n",
    "fs_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b635c9",
   "metadata": {},
   "source": [
    "### Generate dictionary with plate and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea81cb76-72cf-4b74-b839-60fbec683e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['localhost220513100001_KK22-05-198_FactinAdjusted_sc_feature_selected.parquet', 'localhost220512140003_KK22-05-198_sc_feature_selected.parquet', 'localhost230405150001_sc_feature_selected.parquet', 'localhost231120090001_sc_feature_selected.parquet'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(17995, 667), (43204, 799), (20323, 673), (16887, 657)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load feature data into a dictionary, keyed on plate name\n",
    "cp_dfs = {x.split(\"/\")[-1]: pd.read_parquet(x) for x in fs_files}\n",
    "\n",
    "# Print out useful information about each dataset\n",
    "print(cp_dfs.keys())\n",
    "[cp_dfs[x].shape for x in cp_dfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838a423",
   "metadata": {},
   "source": [
    "### Fit UMAP for whole plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e20a76d-e486-4fe4-ab87-70d3cf8d3502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17995, 2)\n",
      "(43204, 2)\n",
      "(20323, 2)\n",
      "(16887, 2)\n"
     ]
    }
   ],
   "source": [
    "# Fit UMAP features per dataset and save\n",
    "for plate in cp_dfs:\n",
    "    # Set plate name\n",
    "    plate_name = pathlib.Path(plate).stem\n",
    "    # Set output file for the UMAP\n",
    "    output_umap_file = pathlib.Path(output_dir, f\"UMAP_{plate_name}.tsv.gz\")\n",
    "\n",
    "    # # Check if the output file already exists\n",
    "    # if output_umap_file.exists():\n",
    "    #     print(f\"Skipping {output_umap_file.stem} as it already exists.\")\n",
    "    #     continue\n",
    "\n",
    "    # Make sure to reinitialize UMAP instance per plate\n",
    "    umap_fit = umap.UMAP(\n",
    "        random_state=umap_random_seed,\n",
    "        n_components=umap_n_components\n",
    "    )\n",
    "    \n",
    "    # Remove NA columns\n",
    "    cp_df = cp_dfs[plate]\n",
    "    cp_df = feature_select(\n",
    "        cp_df,\n",
    "        operation=\"drop_na_columns\",\n",
    "        na_cutoff=0\n",
    "    )\n",
    "    \n",
    "    # Process cp_df to separate features and metadata\n",
    "    cp_features = infer_cp_features(cp_df)\n",
    "    meta_features = infer_cp_features(cp_df, metadata=True)\n",
    "    \n",
    "    # Fit UMAP and convert to pandas DataFrame\n",
    "    embeddings = pd.DataFrame(\n",
    "        umap_fit.fit_transform(cp_df.loc[:, cp_features]),\n",
    "        columns=[f\"UMAP{x}\" for x in range(0, umap_n_components)]\n",
    "    )\n",
    "    print(embeddings.shape)\n",
    "    \n",
    "    # Combine with metadata\n",
    "    cp_umap_with_metadata_df = pd.concat([\n",
    "        cp_df.loc[:, meta_features],\n",
    "        embeddings\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Generate output file, drop unnamed column, and save \n",
    "    cp_umap_with_metadata_df.to_csv(output_umap_file, index=False, sep=\"\\t\")\n",
    "\n",
    "    # Print an example output file\n",
    "    cp_umap_with_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49874858",
   "metadata": {},
   "source": [
    "## Generate embeddings for filtered data\n",
    "\n",
    "Note: We are filtering out single-cells from plates 3 and 4 where there is more than 1 single-cell adjacent. We are looking to see the impact on the UMAP when only including \"isolated\" single-cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6865f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['localhost230405150001', 'localhost220512140003_KK22-05-198', 'localhost231120090001', 'localhost220513100001_KK22-05-198_FactinAdjusted', 'localhost240201110001']\n"
     ]
    }
   ],
   "source": [
    "# Set random seed as 0 for filtered datasets\n",
    "filtered_umap_random_seed = 0\n",
    "\n",
    "# Select only the feature selected files\n",
    "file_suffix = \"*sc_annotated.parquet\"\n",
    "\n",
    "# Obtain file paths for all annotated plates (contains neighbors data)\n",
    "annot_files = glob.glob(f\"{data_dir}/{file_suffix}\")\n",
    "\n",
    "plate_names = []\n",
    "\n",
    "for file_path in pathlib.Path(\"../../../0.download_data/Images\").iterdir():\n",
    "    plate_names.append(str(file_path.stem))\n",
    "\n",
    "print(plate_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0509049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['localhost230405150001', 'localhost231120090001'])\n",
      "The shapes of the feature selected data frames are: [(20323, 673), (16887, 657)]\n",
      "The shapes of the annotated data frames are: [(20323, 2022), (16887, 2022)]\n"
     ]
    }
   ],
   "source": [
    "# create plate info dictionary\n",
    "plate_info_dictionary = {\n",
    "    name: {\n",
    "        \"fs_data\": pd.read_parquet(\n",
    "            pathlib.Path(\n",
    "                list(data_dir.rglob(f\"{name}_sc_feature_selected.parquet\"))[0]\n",
    "            ).resolve(strict=True)\n",
    "        ),\n",
    "        \"annot_data\": pd.read_parquet(\n",
    "            pathlib.Path(\n",
    "                list(data_dir.rglob(f\"{name}_sc_annotated.parquet\"))[0]\n",
    "            ).resolve(strict=True)\n",
    "        ),\n",
    "    }\n",
    "    for name in plate_names\n",
    "    if name == \"localhost230405150001\" or name == \"localhost231120090001\"\n",
    "}\n",
    "\n",
    "# view the dictionary info to assess that all info is added correctly\n",
    "print(plate_info_dictionary.keys())\n",
    "print(\n",
    "    \"The shapes of the feature selected data frames are:\",\n",
    "    [plate_info_dictionary[x][\"fs_data\"].shape for x in plate_info_dictionary],\n",
    ")\n",
    "print(\n",
    "    \"The shapes of the annotated data frames are:\",\n",
    "    [plate_info_dictionary[x][\"annot_data\"].shape for x in plate_info_dictionary],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93bc951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1705, 2)\n",
      "(2736, 2)\n"
     ]
    }
   ],
   "source": [
    "for plate, info in plate_info_dictionary.items():\n",
    "    # Set output file for the UMAP\n",
    "    output_umap_file = pathlib.Path(output_dir, f\"UMAP_{plate}_fs_filtered.tsv.gz\")\n",
    "\n",
    "    # # Check if the output file already exists\n",
    "    # if output_umap_file.exists():\n",
    "    #     print(f\"Skipping {output_umap_file.stem} as it already exists.\")\n",
    "    #     continue\n",
    "\n",
    "    # Give variable names to data frames\n",
    "    fs_df = info[\"fs_data\"]\n",
    "    annot_df = info[\"annot_data\"]\n",
    "\n",
    "    # Merging neighbor column onto fs_df from annot_df\n",
    "    fs_df = fs_df.merge(\n",
    "        annot_df[[\n",
    "            \"Metadata_Well\", \"Metadata_Site\", \"Metadata_Nuclei_Number_Object_Number\", \"Cells_Neighbors_NumberOfNeighbors_Adjacent\"\n",
    "        ]],\n",
    "        on=[\"Metadata_Well\", \"Metadata_Site\", \"Metadata_Nuclei_Number_Object_Number\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # Rename neighbors column to include as metadata\n",
    "    fs_df = fs_df.rename(columns={\"Cells_Neighbors_NumberOfNeighbors_Adjacent\": \"Metadata_Neighbors_Adjacent\"})\n",
    "\n",
    "    # Only including rows where Metadata_Neighbors_Adjacent is less than or equal to 1 neighbor\n",
    "    filtered_fs_df = fs_df[fs_df['Metadata_Neighbors_Adjacent'] <= 1]\n",
    "\n",
    "    # Reset index to avoid any issues with concat\n",
    "    filtered_fs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Make sure to reinitialize UMAP instance per plate (uses random seed 0 and same umap components as above)\n",
    "    umap_fit = umap.UMAP(\n",
    "        random_state=filtered_umap_random_seed,\n",
    "        n_components=umap_n_components\n",
    "    )\n",
    "\n",
    "    # Remove NA columns\n",
    "    filtered_fs_df = feature_select(\n",
    "        filtered_fs_df,\n",
    "        operation=\"drop_na_columns\",\n",
    "        na_cutoff=0\n",
    "    )\n",
    "    \n",
    "    # Process filtered_fs_df to separate features and metadata\n",
    "    cp_features = infer_cp_features(filtered_fs_df)\n",
    "    meta_features = infer_cp_features(filtered_fs_df, metadata=True)\n",
    "    \n",
    "    # Fit UMAP and convert to pandas DataFrame\n",
    "    embeddings = pd.DataFrame(\n",
    "        umap_fit.fit_transform(filtered_fs_df.loc[:, cp_features]),\n",
    "        columns=[f\"UMAP{x}\" for x in range(0, umap_n_components)]\n",
    "    )\n",
    "    print(embeddings.shape)\n",
    "    \n",
    "    # Combine with metadata\n",
    "    filtered_umap_with_metadata_df = pd.concat([\n",
    "        filtered_fs_df.loc[:, meta_features],\n",
    "        embeddings\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Generate output file, drop unnamed column, and save \n",
    "    filtered_umap_with_metadata_df.to_csv(output_umap_file, index=False, sep=\"\\t\")\n",
    "\n",
    "    # Print an example output file\n",
    "    filtered_umap_with_metadata_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
